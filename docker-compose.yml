version: '3.4'


x-airflow-env:
  &airflow-env
  - LOAD_EX=n
  - AIRFLOW_HOST=webserver
  - AIRFLOW_PORT=8080
  - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
  - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/1
  - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres:5432/airflow
  - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
  - AIRFLOW__CORE__FERNET_KEY='81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs='
  - AIRFLOW__WEBSERVER__SECRET_KEY='WmZHRmJwd1dCUEp6Xl4zVA=='
  - AIRFLOW__WEBSERVER__SECRET_KEY_CMD='WmZHRmJwd1dCUEp6Xl4zVA=='
  - AIRFLOW__WEBSERVER__SECRET_KEY_SECRET='WmZHRmJwd1dCUEp6Xl4zVA=='
  - AIRFLOW__API__ENABLE_EXPERIMENTAL_API=True
  - AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.default
  - DEPLOYMENT_ENV=ci
  - GOOGLE_APPLICATION_CREDENTIALS=/home/airflow/.config/gcloud/credentials.json
  - DATA_SCIENCE_SOURCE_DATASET=${DATA_SCIENCE_SOURCE_DATASET}
  - DATA_SCIENCE_OUTPUT_DATASET=${DATA_SCIENCE_OUTPUT_DATASET}
  - DATA_SCIENCE_STATE_PATH=${DATA_SCIENCE_STATE_PATH}


services:

  jupyter:
    build:
      context: .
      dockerfile: Dockerfile.jupyter
    image: elifesciences/data-science-dags-jupyter:${IMAGE_TAG}
    command: start-notebook.sh --NotebookApp.token=''
    ports:
      - "${DATA_SCIENCE_DAGS_JUPYTER_PORT}:8888"
    volumes:
      # we need the notebooks mount to run the tests (since we don't copy them in)
      - ./notebooks:/home/jovyan/data-science-dags/notebooks
  
  airflow-image:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: elifesciences/data-science-airflow-dag:${IMAGE_TAG}
    command: /bin/sh -c exit 0
    entrypoint: []

  airflow-dev:
    environment:
      - DEPLOYMENT_ENV=ci
    build:
      context: .
      dockerfile: Dockerfile.airflow
      args:
        install_dev: y
    image:  elifesciences/data-science-airflow-dag-dev:${IMAGE_TAG}
    command: /bin/sh -c exit 0
    entrypoint: []

  webserver:
    depends_on:
      - worker
    environment: *airflow-env
    volumes:
      - ./config/webserver_config.py:/opt/airflow/webserver_config.py
    image: elifesciences/data-science-airflow-dag:${IMAGE_TAG}
    entrypoint: /entrypoint
    command: webserver

  scheduler:
    image: elifesciences/data-science-airflow-dag:${IMAGE_TAG}
    depends_on:
      - postgres
    environment: *airflow-env
    entrypoint: /entrypoint
    command: scheduler

  test-client:
    image: elifesciences/data-science-airflow-dag:${IMAGE_TAG}
    depends_on:
      - scheduler
      - webserver
    environment: *airflow-env
    command: >
      bash -c "sudo install -D /tmp/credentials.json -m 644 -t  /home/airflow/.config/gcloud
      && ./run_test.sh with-end-to-end"
    
  worker:
    environment: *airflow-env
    depends_on:
      - redis
      - scheduler
    image: elifesciences/data-science-airflow-dag:${IMAGE_TAG}
    entrypoint: /entrypoint
    hostname: worker
    command: >
        bash -c "sudo install -D /tmp/credentials.json -m 644 -t /home/airflow/.config/gcloud
        && sudo install -D /tmp/.aws-credentials -m 644 --no-target-directory /home/airflow/.aws/credentials
        && airflow celery worker"

  postgres:
    image: postgres:9.6
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      timeout: 5s
      retries: 5
  redis:
    image: redis:5.0.5
    environment:
        - ALLOW_EMPTY_PASSWORD=yes

  flower:
    image: elifesciences/data-hub-ejp-xml-pipeline-dev
    depends_on:
        - redis
    environment: *airflow-env
    ports:
        - "5555:5555"
    command: celery flower

  peerscout-api:
    build:
      context: .
      dockerfile: Dockerfile.peerscout_api
      target: runtime
    image: elifesciences/data-science-dags_peerscout-api:${IMAGE_TAG}
    environment:
      - PEERSCOUT_API_URL=http://peerscout-api:8080/api/peerscout

  peerscout-api-dev:
    build:
      context: .
      dockerfile: Dockerfile.peerscout_api
      target: dev
    image: elifesciences/data-science-dags_peerscout-api_dev:${IMAGE_TAG}
    environment: 
      - PEERSCOUT_API_URL=http://peerscout-api:8080/api/peerscout
  
  wait-for-it:
    image: willwill/wait-for-it

volumes:
  data:
