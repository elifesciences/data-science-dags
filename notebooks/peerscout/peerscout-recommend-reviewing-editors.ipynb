{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "project_id = 'elife-data-pipeline'\n",
    "source_dataset = 'de_dev'\n",
    "output_dataset = 'de_dev'\n",
    "output_table_prefix = 'data_science_'\n",
    "max_manuscripts = None\n",
    "manuscript_min_tf = 10\n",
    "manuscript_max_tf = 0.9\n",
    "state_path = 's3://ci-elife-data-pipeline/airflow-config/data-science/state-dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from typing import List, Tuple, TypeVar, Iterable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from google.cloud.bigquery import WriteDisposition\n",
    "\n",
    "import data_science_pipeline.configure_warnings  # pylint: disable=unused-import\n",
    "import data_science_pipeline.configure_notebook_logging  # pylint: disable=unused-import\n",
    "\n",
    "from data_science_pipeline.sql import get_sql\n",
    "from data_science_pipeline.utils.bq import (\n",
    "    load_file_into_bq_with_auto_schema,\n",
    "    with_limit_sql\n",
    ")\n",
    "from data_science_pipeline.utils.io import load_object_from\n",
    "from data_science_pipeline.utils.jupyter import (\n",
    "    read_big_query as _read_big_query\n",
    ")\n",
    "from data_science_pipeline.peerscout.models import (\n",
    "    WeightedKeywordModel\n",
    ")\n",
    "from data_science_pipeline.utils.json import (\n",
    "    remove_key_with_null_value,\n",
    "    json_list_as_jsonl_file\n",
    ")\n",
    "from data_science_pipeline.utils.editor_recommendation import (\n",
    "    get_author_ids_of_given_version_of_manuscript\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(state_path, 'reviewing_editor_model.joblib')\n",
    "recommendation_output_table_name = '{prefix}{suffix}'.format(\n",
    "    prefix=output_table_prefix,\n",
    "    suffix='reviewing_editor_recommendation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading model from:', model_path)\n",
    "model_dict = load_object_from(model_path)\n",
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_tf_idf_vectorizer = model_dict['editor_tf_idf_vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_tf_idf = model_dict['editor_tf_idf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_names = model_dict['editor_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_person_ids = model_dict['editor_person_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_person_id_by_name_map = dict(zip(editor_names, editor_person_ids))\n",
    "editor_person_id_by_name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_keyword_valid_model = WeightedKeywordModel.from_tf_matrix(\n",
    "    editor_tf_idf.todense(),\n",
    "    vectorizer=editor_tf_idf_vectorizer,\n",
    "    choices=editor_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_big_query = partial(_read_big_query, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_query_props = dict(project=project_id, dataset=source_dataset)\n",
    "default_query_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using the same manuscript list used for senior editor recommendation\n",
    "# this is because we want to recommend reviewing editors to consult with (not for assignment)\n",
    "manuscript_version_for_recommendation_df = read_big_query(with_limit_sql(\n",
    "    get_sql('manuscript-version-initial-submissions-for-senior-editor-recommendation.sql').format(\n",
    "        **default_query_props\n",
    "    ),\n",
    "    limit=max_manuscripts\n",
    "))\n",
    "manuscript_version_for_recommendation_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_similarity = cosine_similarity(\n",
    "    editor_tf_idf_vectorizer.transform(\n",
    "        manuscript_version_for_recommendation_df\n",
    "        ['extracted_keywords']\n",
    "    ),\n",
    "    editor_tf_idf\n",
    ")\n",
    "print(\"max keyword_similarity: \", keyword_similarity.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_keyword_valid_model.predict_ranking(\n",
    "#     manuscript_version_for_recommendation_df['extracted_keywords'][:1],\n",
    "# ).proba_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manuscript_matching_keywords_list = weighted_keyword_valid_model.predict_ranking(\n",
    "    manuscript_version_for_recommendation_df['extracted_keywords']\n",
    ").matching_keywords_list\n",
    "pd.Series(manuscript_matching_keywords_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar('T')\n",
    "\n",
    "\n",
    "def get_recommended_editors_with_probability(\n",
    "        proba_matrix: List[List[float]],\n",
    "        editors_matching_keywords_list: List[List[List[Tuple[float, str]]]],\n",
    "        indices: List[T],\n",
    "        threshold: float = 0.5) -> List[List[Tuple[float, T, float, List[Tuple[float, str]]]]]:\n",
    "    return [\n",
    "        sorted([\n",
    "            (\n",
    "                p,\n",
    "                key,\n",
    "                sum(\n",
    "                    s for s, _ in editor_matching_keywords\n",
    "                ),\n",
    "                editor_matching_keywords\n",
    "            )\n",
    "            for p, key, editor_matching_keywords in zip(\n",
    "                row,\n",
    "                indices,\n",
    "                editors_matching_keywords\n",
    "            ) if p >= threshold\n",
    "        ], reverse=True)\n",
    "        for row, editors_matching_keywords in zip(proba_matrix, editors_matching_keywords_list)\n",
    "    ]\n",
    "\n",
    "\n",
    "prediction_results_with_similarity = pd.Series(\n",
    "    get_recommended_editors_with_probability(\n",
    "        keyword_similarity,\n",
    "        manuscript_matching_keywords_list,\n",
    "        editor_names,\n",
    "        threshold=0.001\n",
    "    ),\n",
    "    index=manuscript_version_for_recommendation_df.index\n",
    ")\n",
    "prediction_results_with_similarity[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_results_df = pd.concat([\n",
    "    manuscript_version_for_recommendation_df['version_id'],\n",
    "    prediction_results_with_similarity.to_frame('prediction'),\n",
    "], axis=1)\n",
    "print(\"len of prediction_results_df: \", len(prediction_results_df))\n",
    "prediction_results_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_results_df['prediction'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"'prediction_results_df' memory usage:\")\n",
    "prediction_results_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manuscript_version_for_recommendation_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_prediction_results(\n",
    "    prediction_df: pd.DataFrame,\n",
    ") -> Iterable[dict]:\n",
    "    for row in prediction_df.itertuples():\n",
    "        for predicted_editor in row.prediction:\n",
    "            person_id = editor_person_id_by_name_map[predicted_editor[1]]\n",
    "            author_ids = get_author_ids_of_given_version_of_manuscript(\n",
    "                manuscript_version_for_recommendation_df,\n",
    "                row.version_id\n",
    "            )\n",
    "            if person_id in author_ids:\n",
    "                print(f\"Excluding person_id: {person_id} who is an author of the paper {row.version_id}.\")\n",
    "                continue\n",
    "            yield remove_key_with_null_value({\n",
    "                'version_id': row.version_id,\n",
    "                'score': predicted_editor[0],\n",
    "                'name': predicted_editor[1],\n",
    "                'person_id': person_id,\n",
    "                'matching_keyword_score': predicted_editor[2],\n",
    "                'matching_keywords': [{\n",
    "                    'score': keyword_score,\n",
    "                    'keyword': keyword\n",
    "                } for keyword_score, keyword in predicted_editor[3]],\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with json_list_as_jsonl_file(iter_prediction_results(prediction_results_df)) as jsonl_file:\n",
    "    load_file_into_bq_with_auto_schema(\n",
    "        jsonl_file = jsonl_file,\n",
    "        project_id = project_id,\n",
    "        write_mode = WriteDisposition.WRITE_TRUNCATE,\n",
    "        dataset_name= output_dataset,\n",
    "        table_name= recommendation_output_table_name,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa0e558d19a230636e19ac4c9ade870c2c276d3dbc1e90e338dc45db7288d529"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
