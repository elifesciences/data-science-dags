{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "project_id = 'elife-data-pipeline'\n",
    "source_dataset = 'de_dev'\n",
    "output_dataset = 'de_dev'\n",
    "output_table_prefix = 'data_science_'\n",
    "manuscript_min_tf = 10\n",
    "manuscript_max_tf = 0.9\n",
    "state_path = 's3://ci-elife-data-pipeline/airflow-config/data-science/state-dev'"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "parameters"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from typing import List, Tuple, T\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import data_science_pipeline.configure_warnings  #pylint: disable=unused-import\n",
    "import data_science_pipeline.configure_notebook_logging  # pylint: disable=unused-import\n",
    "\n",
    "from data_science_pipeline.sql import get_sql\n",
    "from data_science_pipeline.utils.bq import to_gbq\n",
    "from data_science_pipeline.utils.io import load_object_from\n",
    "from data_science_pipeline.utils.jupyter import (\n",
    "    read_big_query as _read_big_query\n",
    ")\n",
    "from data_science_pipeline.peerscout.models import (\n",
    "    WeightedKeywordModel\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model_path = os.path.join(state_path, 'senior_editor_model.joblib')\n",
    "recommendation_output_table_name = '{output_dataset}.{prefix}{suffix}'.format(\n",
    "    output_dataset=output_dataset,\n",
    "    prefix=output_table_prefix,\n",
    "    suffix='editor_recommendation'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print('loading model from:', model_path)\n",
    "model_dict = load_object_from(model_path)\n",
    "model_dict.keys()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading model from: s3://ci-elife-data-pipeline/airflow-config/data-science/state-dev/senior_editor_model.joblib\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/hazal/elife_repo/data-science-dags/venv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/hazal/elife_repo/data-science-dags/venv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['editor_tf_idf_vectorizer', 'editor_tf_idf', 'editor_names', 'editor_person_ids'])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "editor_tf_idf_vectorizer = model_dict['editor_tf_idf_vectorizer']\n",
    "editor_tf_idf_vectorizer"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfVectorizer(lowercase=False, smooth_idf=False, token_pattern=None,\n",
       "                tokenizer=<function identity_fn at 0x1347f3d40>)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "editor_tf_idf = model_dict['editor_tf_idf']\n",
    "editor_tf_idf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<72x21870 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 362280 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "editor_names = model_dict['editor_names']\n",
    "# editor_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "editor_person_ids = model_dict['editor_person_ids']\n",
    "# editor_person_ids"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "editor_person_id_by_name_map = dict(zip(editor_names, editor_person_ids))\n",
    "# editor_person_id_by_name_map"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "weighted_keyword_valid_model = WeightedKeywordModel.from_tf_matrix(\n",
    "    editor_tf_idf.todense(),\n",
    "    vectorizer=editor_tf_idf_vectorizer,\n",
    "    choices=editor_names\n",
    ")\n",
    "# weighted_keyword_valid_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "read_big_query = partial(_read_big_query, project_id=project_id)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "default_query_props = dict(project=project_id, dataset=source_dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "manuscript_version_for_recommendation_df = read_big_query(\n",
    "    get_sql('manuscript-version-initial-submissions-for-senior-editor-recommendation.sql').format(\n",
    "        **default_query_props\n",
    "    )\n",
    ")\n",
    "# print(len(manuscript_version_for_recommendation_df))\n",
    "# manuscript_version_for_recommendation_df.head()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": [
       "> ```sql\n",
       "> -- Main features:\n",
       "> --    - Returns Initial Submissions for the purpose of Senior Editor recommendation\n",
       "> --    - No older than a year\n",
       "> --    - Not have Senior Editor assigned for more than 30 days\n",
       "> \n",
       "> WITH t_manuscript_version_abstract_keywords AS (\n",
       ">   SELECT\n",
       ">     manuscript_abstract_keywords.manuscript_id AS manuscript_id,\n",
       ">     manuscript_abstract_keywords.version_id,\n",
       ">     manuscript_abstract_keywords.extracted_keywords,\n",
       ">     ROW_NUMBER() OVER (\n",
       ">       PARTITION BY version_id\n",
       ">       ORDER BY data_hub_imported_timestamp DESC\n",
       ">     ) AS version_id_row_number\n",
       ">   FROM `elife-data-pipeline.de_dev.manuscript_abstract_keywords` AS manuscript_abstract_keywords\n",
       ">   WHERE ARRAY_LENGTH(extracted_keywords) > 0\n",
       "> ),\n",
       "> \n",
       "> t_last_manuscript_version_abstract_keywords AS (\n",
       ">   SELECT\n",
       ">     * EXCEPT(version_id_row_number)\n",
       ">   FROM t_manuscript_version_abstract_keywords\n",
       ">   WHERE version_id_row_number = 1\n",
       ">   ORDER BY version_id\n",
       "> )\n",
       "> \n",
       "> SELECT version.version_id, manuscript_version_abstract_keywords.extracted_keywords\n",
       "> FROM `elife-data-pipeline.de_dev.mv_manuscript_version` AS version\n",
       "> JOIN t_last_manuscript_version_abstract_keywords AS manuscript_version_abstract_keywords\n",
       ">   ON manuscript_version_abstract_keywords.version_id = version.version_id\n",
       "> WHERE version.overall_stage = 'Initial Submission'\n",
       ">   AND (\n",
       ">     ARRAY_LENGTH(version.senior_editors) = 0\n",
       ">     OR TIMESTAMP_DIFF(\n",
       ">       CURRENT_TIMESTAMP,\n",
       ">       (SELECT MAX(last_assigned_timestamp) FROM UNNEST(version.senior_editors)),\n",
       ">       DAY\n",
       ">     ) < 30\n",
       ">   )\n",
       ">   AND TIMESTAMP_DIFF(CURRENT_TIMESTAMP, version.created_timestamp, DAY) < 365\n",
       ">   AND NOT is_withdrawn\n",
       ">   AND NOT is_deleted\n",
       "> ```"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "keyword_similarity = cosine_similarity(\n",
    "    editor_tf_idf_vectorizer.transform(\n",
    "        manuscript_version_for_recommendation_df\n",
    "        ['extracted_keywords']\n",
    "    ),\n",
    "    editor_tf_idf\n",
    ")\n",
    "# print(keyword_similarity.max())\n",
    "# keyword_similarity"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "weighted_keyword_valid_model.predict_ranking(\n",
    "    manuscript_version_for_recommendation_df['extracted_keywords'][:1],\n",
    ").proba_matrix"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "matrix([[0.05729369, 0.14320046, 0.07224609, 0.10036872, 0.04462025,\n",
       "         0.04714328, 0.22195058, 0.12048519, 0.14570821, 0.05358157,\n",
       "         0.07877081, 0.05734939, 0.04469389, 0.05988373, 0.07402032,\n",
       "         0.03682689, 0.08927674, 0.04702045, 0.05672794, 0.06213534,\n",
       "         0.0536982 , 0.12198293, 0.17261758, 0.04555791, 0.06586447,\n",
       "         0.12794226, 0.06602591, 0.06560843, 0.14865797, 0.05176305,\n",
       "         0.07114613, 0.04574581, 0.13757111, 0.04095361, 0.13444617,\n",
       "         0.24022015, 0.06047642, 0.06682273, 0.06840197, 0.1713528 ,\n",
       "         0.04220274, 0.09644525, 0.05549118, 0.05630301, 0.05294448,\n",
       "         0.04739091, 0.08189801, 0.14288646, 0.0673432 , 0.11320263,\n",
       "         0.04706534, 0.06028706, 0.07645614, 0.05797921, 0.06714612,\n",
       "         0.07376837, 0.1228253 , 0.05903231, 0.07535301, 0.12795652,\n",
       "         0.05065281, 0.17554124, 0.03243371, 0.06103372, 0.06801791,\n",
       "         0.0602241 , 0.11137763, 0.154268  , 0.09766311, 0.07047984,\n",
       "         0.06409865, 0.06348857]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "manuscript_matching_keywords_list = weighted_keyword_valid_model.predict_ranking(\n",
    "    manuscript_version_for_recommendation_df['extracted_keywords']\n",
    ").matching_keywords_list\n",
    "pd.Series(manuscript_matching_keywords_list[:5])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    [[(0.009742938450779979, result), (0.004467759...\n",
       "1    [[(0.01241493083998792, result), (0.0089232315...\n",
       "2    [[(0.010565836818567462, result), (0.005943283...\n",
       "3    [[(0.006733348606335727, gene), (0.00673334860...\n",
       "4    [[(0.023284361697453057, cell), (0.01222169681...\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def get_recommended_editors_with_probability(\n",
    "        proba_matrix: List[List[float]],\n",
    "        editors_matching_keywords_list: List[List[Tuple[float, str]]],\n",
    "        indices: List[T],\n",
    "        threshold: float = 0.5) -> List[List[Tuple[float, T]]]:\n",
    "    return [\n",
    "        sorted([\n",
    "            (\n",
    "                p,\n",
    "                key,\n",
    "                sum(\n",
    "                    s for s, _ in editor_matching_keywords\n",
    "                ),\n",
    "                editor_matching_keywords\n",
    "            )\n",
    "            for p, key, editor_matching_keywords in zip(\n",
    "                row,\n",
    "                indices,\n",
    "                editors_matching_keywords\n",
    "            ) if p >= threshold\n",
    "        ], reverse=True)\n",
    "        for row, editors_matching_keywords in zip(proba_matrix, editors_matching_keywords_list)\n",
    "    ]\n",
    "\n",
    "\n",
    "prediction_results_with_similarity = pd.Series(\n",
    "    get_recommended_editors_with_probability(\n",
    "        keyword_similarity,\n",
    "        manuscript_matching_keywords_list,\n",
    "        editor_names,\n",
    "        threshold=0.001\n",
    "    ),\n",
    "    index=manuscript_version_for_recommendation_df.index\n",
    ")\n",
    "# print(prediction_results_with_similarity[0])\n",
    "# prediction_results_with_similarity[:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "prediction_results_df = pd.concat([\n",
    "    manuscript_version_for_recommendation_df['version_id'],\n",
    "    prediction_results_with_similarity.to_frame('prediction'),\n",
    "], axis=1)\n",
    "# print(len(prediction_results_df))\n",
    "# prediction_results_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# prediction_results_df['prediction'][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "prediction_results_flat_df = pd.DataFrame([\n",
    "    {\n",
    "        'version_id': row.version_id,\n",
    "        'score': predicted_editor[0],\n",
    "        'name': predicted_editor[1],\n",
    "        'person_id': editor_person_id_by_name_map[predicted_editor[1]],\n",
    "        'matching_keyword_score': predicted_editor[2],\n",
    "        'matching_keywords': [{\n",
    "            'score': keyword_score,\n",
    "            'keyword': keyword\n",
    "        } for keyword_score, keyword in predicted_editor[3]],\n",
    "    }\n",
    "    for row in prediction_results_df.itertuples()\n",
    "    for predicted_editor in row.prediction\n",
    "])\n",
    "# print(len(prediction_results_flat_df))\n",
    "# prediction_results_flat_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "prediction_results_flat_df['version_id'].nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "prediction_results_flat_df.max()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/hazal/elife_repo/data-science-dags/venv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "version_id                72268/2021-07-16T19:01:37Z\n",
       "score                                       0.304983\n",
       "name                                   Wendy Garrett\n",
       "person_id                                      97155\n",
       "matching_keyword_score                      0.304983\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "print('writing to:', recommendation_output_table_name)\n",
    "to_gbq(\n",
    "    prediction_results_flat_df,\n",
    "    recommendation_output_table_name,\n",
    "    project_id=project_id,\n",
    "    if_exists='replace'\n",
    ")\n",
    "print('done')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "writing to: de_dev.data_science_editor_recommendation\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:root:Processing line 1000\n",
      "INFO:root:Processed 1725 lines\n",
      "INFO:data_science_pipeline.utils.bq:loading from /var/folders/gz/3b4st4q56pd1983txrbt2yyw0000gn/T/tmpa_3iplwk/data.jsonl.gz\n",
      "INFO:data_science_pipeline.utils.bq:Loaded 1725 rows into de_dev:data_science_editor_recommendation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "interpreter": {
   "hash": "fa0e558d19a230636e19ac4c9ade870c2c276d3dbc1e90e338dc45db7288d529"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}